{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/miniconda3/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /opt/miniconda3/lib/python3.12/site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in /opt/miniconda3/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/miniconda3/lib/python3.12/site-packages (from nltk) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/trentyoung/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/trentyoung/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/trentyoung/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in /opt/miniconda3/lib/python3.12/site-packages (0.11.7)\n",
      "Requirement already satisfied: pdfminer.six==20250506 in /opt/miniconda3/lib/python3.12/site-packages (from pdfplumber) (20250506)\n",
      "Requirement already satisfied: Pillow>=9.1 in /opt/miniconda3/lib/python3.12/site-packages (from pdfplumber) (11.1.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /opt/miniconda3/lib/python3.12/site-packages (from pdfplumber) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/miniconda3/lib/python3.12/site-packages (from pdfminer.six==20250506->pdfplumber) (3.4.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/miniconda3/lib/python3.12/site-packages (from pdfminer.six==20250506->pdfplumber) (44.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/miniconda3/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/miniconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# libraries for text cleaning\n",
    "%pip install nltk\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords as sw\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# library to read the PDF\n",
    "%pip install pdfplumber\n",
    "import pdfplumber\n",
    "\n",
    "# convert date string to datetime format\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should use this code\n",
    "# this is the text extracted from the first 3 pages extracted from the\n",
    "def raw_data_extraction(input_pdf):\n",
    "    # take the pdf as an input and return the whole pdf as text\n",
    "    raw_input=\"\"\n",
    "    with pdfplumber.open(input_pdf) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            raw_input+=(page.extract_text() or \"\") + \"\\n\"\n",
    "    return raw_input\n",
    "\n",
    "def article_extraction(raw_input):\n",
    "    #all_news = re.sub(r'\\([^)]*\\)', '', raw_input)\n",
    "    #sww=set(sw.words())\n",
    "    article=\"\"\n",
    "    details=\"\"\n",
    "    article_status=False # mark the start of the article\n",
    "    details_status=False\n",
    "    for row in raw_input.lower().split('\\n'):\n",
    "        if row=='full text':\n",
    "            article_status=True\n",
    "            continue\n",
    "        if article_status:\n",
    "            if row=='details':\n",
    "                article_status=False\n",
    "                details_status=True\n",
    "                continue\n",
    "            article+=row+\" \"\n",
    "        if details_status:\n",
    "            if row=='links':\n",
    "                details_status=False\n",
    "                continue\n",
    "            details+=row+'\\n'\n",
    "    return article, details\n",
    "\n",
    "def clean_article(article):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    desc = re.sub(r'\\([^)]*\\)', '', article)\n",
    "    sent_desc =sent_tokenize(desc)\n",
    "    sww=set(sw.words())\n",
    "    abstraction = []\n",
    "    for sent in sent_desc:\n",
    "        tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent.lower())\n",
    "        words = word_tokenize(tokens)\n",
    "        remaining_words = [word for word in words if word not in sww]\n",
    "        if remaining_words:\n",
    "            lemmatised_words=[]\n",
    "            for word in remaining_words:\n",
    "                lemmatised_word=lemmatizer.lemmatize(word)\n",
    "                lemmatised_words.append(lemmatised_word)\n",
    "            abstraction.append(lemmatised_words)\n",
    "    final_doc=\"\"\n",
    "    for sent in abstraction[:-1]:\n",
    "        for word in sent:\n",
    "            final_doc+=word+\" \"\n",
    "    return final_doc # remove the name of the writer\n",
    "\n",
    "def clean_detail(detail):\n",
    "    for row in detail.split('\\n'):\n",
    "        if row.split(\":\")[0]==\"publication date\":\n",
    "            format_date= \" %b %d, %Y\"           \n",
    "            date_format = datetime.strptime(row.split(\":\")[1], format_date)\n",
    "            return date_format.date()\n",
    "    \n",
    "\n",
    "raw_input1=raw_data_extraction('3pages.pdf')\n",
    "article1, details1=article_extraction(raw_input1)\n",
    "doc1=clean_article(article1)\n",
    "date1=clean_detail(details1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conservative economist erwin john antoni joke social medium bls silent president trump week tapped antoni run bureau labor statistic agency data methodology long criticized especially produce number trump antoni recently proposed suspending monthly job report important data release economy market tuesday white house official noted antoni made comment knew chosen comment reflect official bls policy confirmed senate antoni run 141 year agency staffed 2 000 economist statistician official bls long record independence nonpartisanship economist investor critical credibility economic data commencement program northern illinois university antoni earned master ph economics school 2018 2020 respectively bachelor art st charles borromeo seminary antoni linkedin profile attended lansdale catholic high school philadelphia 2002 2006 profile antoni work 2021 economist texas public policy foundation conservative tank austin sued federal government overturn climate change regulation year joined conservative heritage foundation research fellow studying regional economics foundation chief economist adviser committee unleash prosperity group conservative economic commentator past bls commissioner extensive research experience climbed agency rank antoni fit profile published formal academic research dissertation query national bureau economic research working paper google scholar commentary heritage website praise trump policy economic record frequently post x appears wing podcasts former trump adviser steve bannon room criticized economy president joe biden lauds trump economy heritage foundation declined make antoni available interview respond question background antoni linkedin profile ph concentration fiscal policy labor economics dissertation file northern illinois principally analyzes fiscal policy crowding effect deficit spending effect state tax domestic migration called irrelevance credit rating municipal debt yield google scholar antoni paper earned citation texas public policy foundation 2021 worked publication erika mcentarfer bls commissioner trump ousted aug 1 midway term cited 1 327 time trump fired mcentarfer report showing significant downward revision prior month job growth matter making number matter accurate antoni bannon aug 1 show mcentarfer dismissal model methodology revised antoni told fox news digital interview aug 4 bls suspend issuing monthly job report changed methodology move unprecedented leaving public market vital source information economy health commentary data partisan biden final year office antoni argued consumer price index understating inflation july 2024 monthly rent data stale real cost show election fact bls data showed rent rising slowly private data 2021 22 2024 reverse showed rent 5 2 june year earlier compared 3 2 zillow bannon aug 1 show wrongly biden removed mcentarfer predecessor bill beach trump appointed 2019 fact beach remained job year term expired 2023 beach grateful conservative praised trump choice antoni sharpest economic mind nation fearless truth teller grasp sound economics serve interest american family globalist elite heritage foundation president kevin robert statement independent economist unqualified lot competent conservative economist job kyle pomerleau senior fellow center american enterprise institute social medium post bill cassidy chairman senate committee health education labor pension statement bls commissioner committed producing accurate unbiased economic information american chairman cassidy forward meeting dr antoni discus accomplish move backfire data unreliable installing partisan commissioner bureau labor statistic prove counterproductive president trump renaissance macro research economist neil dutta antoni prod agency producing statistic flatter administration data credible delay interest rate cut federal reserve scenario work president benefit dutta bill beach bls commissioner appointed trump term antoni suggestion suspending publication monthly job report idea shoring trust data fix thing publishing make extremely transparent beach antoni buffer white house agency \n"
     ]
    }
   ],
   "source": [
    "print(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2025, 8, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "strptime() argument 1 must be str, not datetime.date",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m      2\u001b[0m format_date\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m date_object \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(date_object\u001b[38;5;241m.\u001b[39mdate())\n",
      "\u001b[0;31mTypeError\u001b[0m: strptime() argument 1 must be str, not datetime.date"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "format_date= \" %b %d, %Y\"\n",
    "date_object = datetime.strptime(date1, format_date)\n",
    "print(date_object.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subject: conservatism; fiscal policy; presidents; economists; public policy; economics;',\n",
       " 'congressional committees',\n",
       " 'business indexing term: subject: fiscal policy economists economics; corporation: linkedin corp; industry:',\n",
       " '92111 : executive offices 92112 : legislative bodies',\n",
       " 'location: texas; united states--us',\n",
       " 'people: trump, donald j; antoni, erwin john iii',\n",
       " 'company / organization: name: linkedin corp; naics: 518210; name: bureau of labor statistics; naics: 921110,',\n",
       " '923110; name: texas public policy foundation; naics: 813211; name: heritage',\n",
       " 'foundation-washington dc; naics: 541720',\n",
       " 'classification: 92111: executive offices; 92112: legislative bodies',\n",
       " 'publication title: wall street journal, eastern edition; new york, n.y.',\n",
       " 'first page: a2',\n",
       " 'publication year: 2025',\n",
       " 'publication date: aug 14, 2025',\n",
       " 'publisher: dow jones &company inc.',\n",
       " 'place of publication: new york, n.y.',\n",
       " 'country of publication: united states',\n",
       " 'publication subject: business and economics--banking and finance',\n",
       " 'issn: 00999660',\n",
       " 'source type: newspaper',\n",
       " 'language of publication: english',\n",
       " 'document type: news',\n",
       " 'proquest document id: 3239236707',\n",
       " 'document url: https://www.proquest.com/newspapers/u-s-news-bls-pick-has-forged-partisan-',\n",
       " 'path/docview/3239236707/se-2?accountid=14681',\n",
       " 'copyright: copyright 2025 dow jones &company, inc. all rights reserved.',\n",
       " 'full text availability: this publication may be subject to restrictions within certain markets, including',\n",
       " 'corporations, non-profits, government institutions, and public libraries. in those cases',\n",
       " 'records will be visible to users, but not full text.',\n",
       " 'last updated: 2025-08-14',\n",
       " 'database: proquest central',\n",
       " '']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details1.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the set of fiscal policy related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the set of recurring words in these articles related to fiscal policy\n",
    "fiscal_terms=['tariffs', 'tax cuts', 'budget deficits', 'presidents', 'fiscal policy', 'political campaigns', 'federal budget', 'economic growth', 'interest rates',\n",
    "                'tax increases', 'gross domestic product-gdp', 'tax rates', 'economists', 'government spending', 'investments', 'voters', 'inflation', 'legislators', 'taxes',\n",
    "                'federal reserve monetory policy', 'investors', 'presidential elections', 'congressional committees', 'borrowing', 'central banks', 'immigration policy', \n",
    "                'international trade', 'economic conditions', 'legislation', 'american dollar', 'social security', 'dow jones averages', 'pandemics', 'treasuries', 'costs',\n",
    "                'funding', 'manufacturing', 'political leadership', 'clean technology', 'national debt', 'national security', 'stocks', 'exports', 'immigrants',\n",
    "                'leadership', 'medicare', 'political parties', 'prime ministers', 'scandals', 'tax credits', 'trade policy', 'border security', 'consumer price index',\n",
    "                'defense spending', 'economic impact', 'economic policy', 'employees', 'federal legislation', 'households', 'immigration', 'international relations', 'low income groups',\n",
    "                'prices', 'social networks', 'tax legislation', 'trade disputes', 'budgets', 'consumers', 'corporate profits', 'currency', 'deportation', \n",
    "                'infrastructure', 'international economic relations', 'nominations', 'nvidia corp', 'polls & surveys', 'provisions', 'recessions', 'securities markets',\n",
    "                'trade relations', 'bond markets', 'cities', 'consumptions', 'cost control', 'decision making', 'deficit financing', 'economic crisis', 'economic development enforcement', \n",
    "                'factories', 'federal funding', 'global economy', 'government bonds', 'income taxes', 'international relations-us', 'profits', 'stock exchanges', 'supply chains', 'tax refunds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group all terms into groups\n",
    "terms_categories={'tax': ['tax cuts','tax increases', 'tax rates', 'tax credits', 'taxes', 'tax legislation', 'income taxes', 'tax refunds', 'corporate profits', 'profits'],\n",
    "                'tariffs_trade': ['tariffs', 'trade policy', 'trade disputes','international trade','trade relations', 'exports','supply chains', 'border security', 'international relations-us', 'international relations', 'immigration policy', 'immigrants', 'immigration', 'deportation'],\n",
    "                'budget_debt': ['budget deficits', 'federal budget', 'budgets', 'deficit financing', 'national debt', 'treasuries', 'borrowing', 'federal funding', 'funding', 'cost control', 'costs', 'investments', 'provisions'],\n",
    "                'spending_social_program': ['government spending', 'defense spending', 'infrastructure', 'social security', 'medicare', 'federal legislation', 'households', 'low income groups', 'national security', 'pandemics', 'manufacturing'],\n",
    "                'monetary_financial_policy': ['government bonds', 'bond markets', 'federal reserve monetory policy', 'central banks', 'stocks', 'stock exchanges', 'dow jones averages','american dollar', 'currency', 'securities markets', 'fiscal policy', 'interest rates', 'inflation', 'consumer price index', 'prices', 'recessions', 'enforcement'],\n",
    "                'economy': ['economists', 'economic growth', 'economic conditions', 'economic policy', 'economic impact', 'international economic relations', 'global economy', 'economic crisis', 'economic development', 'gross domestic product-gdp', 'economic development enforcement'],\n",
    "                'other_context': ['presidents', 'investors', 'political campaigns', 'political leadership', 'political parties', 'legislation','congressional committees','prime ministers','scandals','nominations', 'clean technology', 'cities', 'voters', 'legislators', 'leadership', 'consumers', 'social networks', 'presidential elections', 'nvidia corp', 'polls & surveys', 'consumptions', 'decision making','employees', 'factories']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'terms_groups' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# GONNA DELETE IT LATER\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# check for missing words not in the dictionary -  ensure it could not print anything\u001b[39;00m\n\u001b[1;32m      3\u001b[0m check_list\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mterms_groups\u001b[49m\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m      6\u001b[0m         check_list\u001b[38;5;241m.\u001b[39mappend(word)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'terms_groups' is not defined"
     ]
    }
   ],
   "source": [
    "# GONNA DELETE IT LATER\n",
    "# check for missing words not in the dictionary -  ensure it could not print anything\n",
    "check_list=[]\n",
    "for list in terms_groups.values():\n",
    "    for word in list:\n",
    "        check_list.append(word)\n",
    "\n",
    "for word in fiscal_terms:\n",
    "    if word not in check_list:\n",
    "        print(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match the terms and categories with the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fiscal policy': 2, 'inflation': 1, 'consumer price index': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match the fiscal terms to the document\n",
    "def count_matching_words(terms_list, document):\n",
    "    terms_count={}\n",
    "    for term in terms_list:\n",
    "        term_count=document.count(term)\n",
    "        if term_count>0:\n",
    "            terms_count[term]=term_count\n",
    "    return terms_count\n",
    "\n",
    "count_matching_words(fiscal_terms,doc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'monetary_financial_policy': 4}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match the fiscal term groups to the document\n",
    "def count_matching_category(terms_categories, document):\n",
    "    terms_list=[word for group in terms_categories.values() for word in group]\n",
    "    terms_count={}\n",
    "    for term in terms_list:\n",
    "        term_count=document.count(term)\n",
    "        if term_count>0:\n",
    "            for key in terms_categories.keys():\n",
    "                if term in terms_categories[key]:\n",
    "                    terms_count[key]=terms_count.get(key,0)+term_count\n",
    "    return terms_count\n",
    "\n",
    "count_matching_category(terms_categories,doc1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: \n",
    "- We need at least one word related to debt, tax and tariff\n",
    "- Doing a dataframe:\n",
    "    + article title\n",
    "    + date\n",
    "    + is_fiscal: 0 or 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the dataframe to store the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names =['article_id', 'terms_count', 'categories_count', 'is_fiscal_article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
